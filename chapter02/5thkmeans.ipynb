{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff44ce55d09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0m_ModelFn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_steps_per_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans_plus_plus_num_retries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_tolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ff44ce55d09d>\u001b[0m in \u001b[0;36m_ModelFn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mall_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_op\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_clusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_clusters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistance_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distance_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_mini_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmini_batch_steps_per_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mini_batch_steps_per_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_seed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkmeans_plus_plus_num_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kmeans_plus_plus_num_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss/raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"A canned Estimator for k-means clustering.\"\"\"\n",
    "\n",
    "# TODO(ccolby): Move clustering_ops.py into this file and streamline the code.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "from tensorflow.contrib.factorization.python.ops import clustering_ops\n",
    "from tensorflow.python.estimator import estimator\n",
    "from tensorflow.python.estimator import model_fn as model_fn_lib\n",
    "from tensorflow.python.estimator.export import export_output\n",
    "from tensorflow.python.feature_column import feature_column as fc\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import metrics\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.summary import summary\n",
    "from tensorflow.python.training import session_run_hook\n",
    "from tensorflow.python.training import training_util\n",
    "\n",
    "\n",
    "class _LossRelativeChangeHook(session_run_hook.SessionRunHook):\n",
    "    def __init__(self, loss_tensor, tolerance):\n",
    "        self._loss_tensor = loss_tensor\n",
    "        self._tolerance = tolerance\n",
    "        self. prev_loss = None\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        del run_context  # unused\n",
    "        return session_run_hook.SessionRunArgs(self._loss_tensor)\n",
    "    \n",
    "    def after_run(self, run_context, run_values):\n",
    "        loss = run_values.results\n",
    "        assert loss is not None\n",
    "        if self._prev_loss:\n",
    "            relative_change = (abs(loss - self._prev_loss) / (1 + abs(self._prev_loss)))\n",
    "            if relative_change < self._tolerance:\n",
    "                run_context.request_stop()\n",
    "            self._prev_loss = loss\n",
    "\n",
    "\n",
    "class _InitializeClustersHook(session_run_hook.SessionRunHook):\n",
    "    def __init__(self, init_op, is_initialized_var, is_chief):\n",
    "        self._init_op = init_op\n",
    "        self._is_initialized_var = is_initialized_var\n",
    "        self._is_chief = is_chief\n",
    "\n",
    "    def after_create_session(self, session, coord):\n",
    "        del coord  # unused\n",
    "        assert self._init_op.graph is ops.get_default_graph()\n",
    "        assert self._is_initialized_var.graph is self._init_op.graph\n",
    "        while True:\n",
    "            try:\n",
    "                if session.run(self._is_initialized_var):\n",
    "                    break\n",
    "                elif self._is_chief:\n",
    "                    session.run(self._init_op)\n",
    "                else:\n",
    "                    time.sleep(1)\n",
    "            except RuntimeError as e:\n",
    "                logging.info(e)\n",
    "\n",
    "\n",
    "def _parse_features_if_necessary(features, feature_columns):\n",
    "    if not isinstance(features, dict):\n",
    "        return features\n",
    "    \n",
    "    if feature_columns:\n",
    "        return fc.input_layer(features, feature_columns)\n",
    "    keys = sorted(features.keys())\n",
    "    with ops.colocate_with(features[keys[0]]):\n",
    "        return array_ops.concat([features[k] for k in keys], axis=1)\n",
    "\n",
    "\n",
    "class _ModelFn(object):\n",
    "    def __init__(self, num_clusters, initial_clusters, distance_metric, random_seed, use_mini_batch, mini_batch_steps_per_iteration, kmeans_plus_plus_num_retries, relative_tolerance, feature_columns):\n",
    "        self._num_clusters = num_clusters\n",
    "        self._initial_clusters = initial_clusters\n",
    "        self._distance_metric = distance_metric\n",
    "        self._random_seed = random_seed\n",
    "        self._use_mini_batch = use_mini_batch\n",
    "        self._mini_batch_steps_per_iteration = mini_batch_steps_per_iteration\n",
    "        self._kmeans_plus_plus_num_retries = kmeans_plus_plus_num_retries\n",
    "        self._relative_tolerance = relative_tolerance\n",
    "        self._feature_columns = feature_columns\n",
    "\n",
    "    def model_fn(self, features, mode, config):\n",
    "        input_points = _parse_features_if_necessary(features, self._feature_columns)\n",
    "        (all_distances, model_predictions, losses, is_initialized, init_op, training_op) = clustering_ops.KMeans(inputs=input_points,lusters=self._num_clusters,initial_clusters=self._initial_clusters,distance_metric=self._distance_metric,use_mini_batch=self._use_mini_batch,mini_batch_steps_per_iteration=self._mini_batch_steps_per_iteration,random_seed=self._random_seed,kmeans_plus_plus_num_retries=self._kmeans_plus_plus_num_retries).training_graph()\n",
    "    \n",
    "    loss = math_ops.reduce_sum(losses)\n",
    "    summary.scalar('loss/raw', loss)\n",
    "\n",
    "    incr_step = state_ops.assign_add(training_util.get_global_step(), 1)\n",
    "    training_op = control_flow_ops.with_dependencies([training_op, incr_step],loss)\n",
    "\n",
    "    training_hooks = [\n",
    "        _InitializeClustersHook(init_op, is_initialized, config.is_chief)\n",
    "    ]\n",
    "    \n",
    "    if self._relative_tolerance is not None:\n",
    "        training_hooks.append(\n",
    "            _LossRelativeChangeHook(loss, self._relative_tolerance))\n",
    "        \n",
    "    export_outputs = {\n",
    "        KMeansClustering.ALL_DISTANCES:\n",
    "            export_output.PredictOutput(all_distances[0]),\n",
    "        KMeansClustering.CLUSTER_INDEX:\n",
    "            export_output.PredictOutput(model_predictions[0]),\n",
    "        signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "            export_output.PredictOutput(model_predictions[0])\n",
    "    }\n",
    "return model_fn_lib.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions={\n",
    "            KMeansClustering.ALL_DISTANCES: all_distances[0],\n",
    "            KMeansClustering.CLUSTER_INDEX: model_predictions[0],\n",
    "        },\n",
    "        loss=loss,\n",
    "        train_op=training_op,\n",
    "        eval_metric_ops={KMeansClustering.SCORE: metrics.mean(loss)},\n",
    "        training_hooks=training_hooks,\n",
    "        export_outputs=export_outputs)\n",
    "\n",
    "\n",
    "# TODO(agarwal,ands): support sharded input.\n",
    "class KMeansClustering(estimator.Estimator):\n",
    "    # Valid values for the distance_metric constructor argument.\n",
    "    SQUARED_EUCLIDEAN_DISTANCE = clustering_ops.SQUARED_EUCLIDEAN_DISTANCE\n",
    "    COSINE_DISTANCE = clustering_ops.COSINE_DISTANCE\n",
    "\n",
    "    # Values for initial_clusters constructor argument.\n",
    "    RANDOM_INIT = clustering_ops.RANDOM_INIT\n",
    "    KMEANS_PLUS_PLUS_INIT = clustering_ops.KMEANS_PLUS_PLUS_INIT\n",
    "\n",
    "    # Metric returned by evaluate(): The sum of the squared distances from each\n",
    "    # input point to its closest center.\n",
    "    SCORE = 'score'\n",
    "\n",
    "    # Keys returned by predict().\n",
    "    # ALL_DISTANCES: The distance from each input  point to each cluster center.\n",
    "    # CLUSTER_INDEX: The index of the closest cluster center for each input point.\n",
    "    CLUSTER_INDEX = 'cluster_index'\n",
    "    ALL_DISTANCES = 'all_distances'\n",
    "\n",
    "    # Variable name used by cluster_centers().\n",
    "    CLUSTER_CENTERS_VAR_NAME = clustering_ops.CLUSTERS_VAR_NAME\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_clusters,\n",
    "                 model_dir=None,\n",
    "                 initial_clusters=RANDOM_INIT,\n",
    "                 distance_metric=SQUARED_EUCLIDEAN_DISTANCE,\n",
    "                 random_seed=0,\n",
    "                 use_mini_batch=True,\n",
    "                 mini_batch_steps_per_iteration=1,\n",
    "                 kmeans_plus_plus_num_retries=2,\n",
    "                 relative_tolerance=None,\n",
    "                 config=None,\n",
    "                 feature_columns=None):\n",
    "        if isinstance(initial_clusters, str) and initial_clusters not in [KMeansClustering.RANDOM_INIT, KMeansClustering.KMEANS_PLUS_PLUS_INIT]:\n",
    "            raise ValueError(\"Unsupported initialization algorithm '%s'\" % initial_clusters)\n",
    "        if distance_metric not in [KMeansClustering.SQUARED_EUCLIDEAN_DISTANCE,KMeansClustering.COSINE_DISTANCE]:\n",
    "            raise ValueError(\"Unsupported distance metric '%s'\" % distance_metric)\n",
    "        super(KMeansClustering, self).__init__(\n",
    "        model_fn=_ModelFn(\n",
    "            num_clusters, initial_clusters, distance_metric, random_seed,\n",
    "            use_mini_batch, mini_batch_steps_per_iteration,\n",
    "            kmeans_plus_plus_num_retries, relative_tolerance,\n",
    "            feature_columns).model_fn,\n",
    "        model_dir=model_dir,\n",
    "        config=config)\n",
    "\n",
    "    \n",
    "def _predict_one_key(self, input_fn, predict_key):\n",
    "    for result in self.predict(input_fn=input_fn, predict_keys=[predict_key]):\n",
    "        yield result[predict_key]\n",
    "        \n",
    "def predict_cluster_index(self, input_fn):\n",
    "    for index in self._predict_one_key(input_fn,KMeansClustering.CLUSTER_INDEX):\n",
    "        yield index\n",
    "\n",
    "def score(self, input_fn):\n",
    "    return self.evaluate(input_fn=input_fn, steps=1)[KMeansClustering.SCORE]\n",
    "\n",
    "def transform(self, input_fn):\n",
    "    for distances in self._predict_one_key(input_fn,KMeansClustering.ALL_DISTANCES):\n",
    "        yield distances\n",
    "\n",
    "def cluster_centers(self):\n",
    "    return self.get_variable_value(KMeansClustering.CLUSTER_CENTERS_VAR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
